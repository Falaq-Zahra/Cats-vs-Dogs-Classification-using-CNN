{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Cats vs Dogs Classification using CNN"
      ],
      "metadata": {
        "id": "VVwPJP1RIjCk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dataset: Cats vs Dogs\n",
        "\n",
        "Model: CNN with 3 convolutional layers\n",
        "\n",
        "Loss Function: Binary Crossentropy\n",
        "\n",
        "Optimizer: Adam\n",
        "\n",
        "Output: Interactive Gradio app for real-time predictions"
      ],
      "metadata": {
        "id": "xSwiDIbBIXzc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 1: Extract Dataset"
      ],
      "metadata": {
        "id": "AcXWNjgnIt33"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7B5AMDOOaCVq"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import zipfile\n",
        "zip_path = '/content/archive.zip'   # change this to your actual filename\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall('data/')   # this will create a folder named \"data\"\n"
      ],
      "metadata": {
        "id": "gYvkqmOmfpF0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.listdir('data')\n"
      ],
      "metadata": {
        "id": "OF67tuj1gA4g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 2: Load and Prepare Data"
      ],
      "metadata": {
        "id": "dqodg_XvHrLp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras import Sequential\n",
        "from keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, BatchNormalization, Dropout"
      ],
      "metadata": {
        "id": "X-yH9ND5gaHF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generaters\n",
        "# making batches for large datasets\n",
        "train_ds = keras.utils.image_dataset_from_directory(\n",
        "    directory = '/content/data/train' ,\n",
        "    labels = 'inferred',\n",
        "    label_mode = 'int',\n",
        "    batch_size= 32,\n",
        "    image_size=(256,256)\n",
        ")"
      ],
      "metadata": {
        "id": "hNNz4T1Sguir"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "validation_ds = keras.utils.image_dataset_from_directory(\n",
        "    directory = '/content/data/test' ,\n",
        "    labels = 'inferred',\n",
        "    label_mode = 'int',\n",
        "    batch_size= 32,\n",
        "    image_size=(256,256)\n",
        ")"
      ],
      "metadata": {
        "id": "hbjIH7iijea8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 3: Normalize Pixel Values"
      ],
      "metadata": {
        "id": "DIOMzX1NJDNj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Normalize Pixel value b/w 0 to 1\n",
        "def process(image,label):\n",
        "  image = tf.cast(image/255. ,tf.float32)\n",
        "  return image,label\n",
        "\n",
        "  train_ds = train_ds.map(process)\n",
        "  validation_ds = validation_ds.map(process)"
      ],
      "metadata": {
        "id": "udzLNyffkAEj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 4: Exploratory Data Analysis (EDA)"
      ],
      "metadata": {
        "id": "IlQrIi9d8ZP-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "# Check basic info\n",
        "print(\"Number of training batches:\", tf.data.experimental.cardinality(train_ds).numpy())\n",
        "print(\"Number of validation batches:\", tf.data.experimental.cardinality(validation_ds).numpy())\n",
        "\n",
        "# Get class names\n",
        "class_names = train_ds.class_names\n",
        "print(\"Class names:\", class_names)\n",
        "\n",
        "# Count number of images per class\n",
        "count_dict = {class_name: 0 for class_name in class_names}\n",
        "for images, labels in train_ds.unbatch():\n",
        "    count_dict[class_names[int(labels.numpy())]] += 1\n",
        "print(\"Image count per class:\", count_dict)\n",
        "\n",
        "# Plot class distribution\n",
        "plt.bar(count_dict.keys(), count_dict.values())\n",
        "plt.title(\"Class Distribution in Training Data\")\n",
        "plt.xlabel(\"Class\")\n",
        "plt.ylabel(\"Number of Images\")\n",
        "plt.show()\n",
        "\n",
        "# Show some sample images\n",
        "plt.figure(figsize=(10, 10))\n",
        "for images, labels in train_ds.take(1):\n",
        "    for i in range(9):\n",
        "        ax = plt.subplot(3, 3, i + 1)\n",
        "        plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
        "        plt.title(class_names[labels[i]])\n",
        "        plt.axis(\"off\")\n",
        "plt.show()\n",
        "\n",
        "# Check image shape and data type\n",
        "for image_batch, label_batch in train_ds.take(1):\n",
        "    print(\"Image batch shape:\", image_batch.shape)\n",
        "    print(\"Label batch shape:\", label_batch.shape)\n",
        "    print(\"Pixel value range:\", tf.reduce_min(image_batch).numpy(), \"to\", tf.reduce_max(image_batch).numpy())\n"
      ],
      "metadata": {
        "id": "4YAcaDOY5_Y0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_ds.class_names)\n",
        "for images, labels in train_ds.take(1):\n",
        "    print(labels[:10].numpy())  # show first 10 labels\n",
        "    break\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(10,10))\n",
        "for i in range(9):\n",
        "    ax = plt.subplot(3,3,i+1)\n",
        "    plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
        "    plt.title(train_ds.class_names[labels[i]])\n",
        "    plt.axis(\"off\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "0Sr61UVE7i9M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 5: Build CNN Model"
      ],
      "metadata": {
        "id": "PgO1GCuWJZj-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras import Sequential\n",
        "from keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, BatchNormalization, Dropout\n",
        "\n",
        "# Create CNN model\n",
        "# there would be 3 conv layers\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(32, kernel_size=(3,3), padding='valid', activation='relu', input_shape=(256,256,3)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2,2), strides=2, padding='valid'))\n",
        "\n",
        "model.add(Conv2D(64, kernel_size=(3,3), padding='valid', activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2,2), strides=2, padding='valid'))\n",
        "\n",
        "model.add(Conv2D(128, kernel_size=(3,3), padding='valid', activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2,2), strides=2, padding='valid'))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.1))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dropout(0.1))\n",
        "model.add(Dense(1, activation='sigmoid'))"
      ],
      "metadata": {
        "id": "43vw4ImFjzu8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "4Grxw7UHnybT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 6: Compile and Train Model"
      ],
      "metadata": {
        "id": "CMSA7PXEJfrP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "xIFO0HKXsIyd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(train_ds,epochs=10,validation_data=validation_ds)"
      ],
      "metadata": {
        "id": "907k6wUcsQ0e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 7: Deploy with Gradio"
      ],
      "metadata": {
        "id": "xtuBV2_cJkqr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gradio\n",
        "import gradio as gr\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing import image\n",
        "\n",
        "# If model is already in memory from training, no need to reload\n",
        "# (Otherwise, you can load it like this:)\n",
        "# from tensorflow.keras.models import load_model\n",
        "# model = load_model(\"model.h5\")\n",
        "\n",
        "# Class names as per your dataset\n",
        "class_names = ['cats', 'dogs']  # adjust if directory names differ\n",
        "\n",
        "# Prediction function for Gradio\n",
        "def predict_image(img):\n",
        "    # Resize and preprocess\n",
        "    img = img.resize((256, 256))\n",
        "    img = np.array(img) / 255.0\n",
        "    img = np.expand_dims(img, axis=0)\n",
        "\n",
        "    # Predict\n",
        "    pred = model.predict(img)[0][0]\n",
        "\n",
        "    # Convert to label and confidence\n",
        "    label = class_names[int(pred > 0.5)]\n",
        "    confidence = pred if label == 'dogs' else 1 - pred\n",
        "\n",
        "    return {label: float(confidence)}\n",
        "\n",
        "# Create Gradio interface\n",
        "demo = gr.Interface(\n",
        "    fn=predict_image,\n",
        "    inputs=gr.Image(type=\"pil\", label=\"Upload Cat or Dog Image \"),\n",
        "    outputs=gr.Label(num_top_classes=2),\n",
        "    title=\" Cats vs Dogs Classifier\",\n",
        "    description=\"Upload an image to see if it's a cat or a dog.\",\n",
        ")\n",
        "\n",
        "demo.launch()\n"
      ],
      "metadata": {
        "id": "mDQJ8K68O8pJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 8: Visualize Training Performance"
      ],
      "metadata": {
        "id": "kZEIrlARKrdT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(history.history['accuracy'],color='red',label='train')\n",
        "plt.plot(history.history['val_accuracy'],color='blue',label='validation')\n",
        "plt.legend()\n",
        "plt.show"
      ],
      "metadata": {
        "id": "bAK0fh6Rvjtp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history.history['loss'],color='red',label='train')\n",
        "plt.plot(history.history['val_loss'],color='blue',label='validation')\n",
        "plt.legend()\n",
        "plt.show"
      ],
      "metadata": {
        "id": "71PVfVbLv5Ze"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}